<!DOCTYPE html>
<html>
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Graph Expressive Power</title>
    <meta name="description" content="Project Overview. Based on [*folio](https://github.com/bogoli/-folio) design.">
    <!-- Bootstrap & MDB -->
    <link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />
    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">
    <!-- Styles -->
    <link rel="shortcut icon" href="/graph-power/assets/img/favicon.ico">
    <link rel="stylesheet" href="/graph-power/assets/css/main.css">

    <link rel="canonical" href="/graph-power/">
    <link type="text/css" href="/graph-power/assets/css/magnifier.css" rel="stylesheet">
    <script type="text/javascript" src="/graph-power/assets/js/magnifier.js"></script>
    <!-- KaTeX -->
    <!-- 
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-rc.1/dist/katex.min.css" integrity="sha384-D+9gmBxUQogRLqvARvNLmA9hS2x//eK1FhVb9PiU86gmcrBrJAQT8okdJ4LMp2uv" crossorigin="anonymous">
    <script src="https://cdn.jsdelivr.net/npm/katex@0.10.0-rc.1/dist/katex.min.js" integrity="sha384-483A6DwYfKeDa0Q52fJmxFXkcPCFfnXMoXblOkJ4JcA8zATN6Tm78UNL72AKk+0O" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.0-rc.1/dist/contrib/auto-render.min.js" integrity="sha384-yACMu8JWxKzSp/C1YV86pzGiQ/l1YUfE8oPuahJQxzehAjEt2GiQuy/BIvl9KyeF" crossorigin="anonymous"
        onload="renderMathInElement(document.body);"></script>
     -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.2/dist/katex.min.css" integrity="sha384-Cqd8ihRLum0CCg8rz0hYKPoLZ3uw+gES2rXQXycqnL5pgVQIflxAUDS7ZSjITLb5" crossorigin="anonymous">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.2/dist/katex.min.js" integrity="sha384-1Or6BdeNQb0ezrmtGeqQHFpppNd7a/gw29xeiSikBbsb44xu3uAo8c7FwbF5jhbd" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.2/dist/contrib/auto-render.min.js" integrity="sha384-vZTG03m+2yp6N6BNi5iM4rW4oIwk5DfcNdFfxkk9ZWpDriOkXX8voJBFrAO7MpVl" crossorigin="anonymous"
        onload="renderMathInElement(document.body);"></script>
  </head>
  <body class="fixed-top-nav ">
    <!-- Header -->
    <header>
      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light bg-white navbar-expand-sm fixed-top">
        <div class="container">
          <!-- Navbar Toogle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>
          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">
              <!-- About -->
              <li class="nav-item">
                <a class="nav-link" href="/graph-power/">
                  Abstract
                </a>
              </li>
              <!-- Blog -->
              <li class="nav-item">
                <a class="nav-link" href="/graph-power/blog/UAT/">
                  UAT
                </a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/graph-power/blog/GIT/">
                  GIT
                </a>
              </li>
              <li class="nav-item">
                <a class="nav-link" href="/graph-power/blog/topo/">
                  Topology
                </a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/graph-power/blog/combinatorial/">
                  Combinatorial Problem
                </a>
              </li>
              <li class="nav-item active">
                <a class="nav-link" href="/graph-power/blog/spectral/">
                  Spectral Analysis
                  <span class="sr-only">(current)</span>
                </a>
              </li>
            </ul>
          </div>
        </div>
      </nav>
    </header>
    <!-- Content -->
    <div class="container mt-5">
      <div class="post">
        <header class="post-header">
          <h1 class="post-title">
            <span class="font-weight-bold">A Fourier Analysis Approach of Graph Neural Network Expressive Power</span>
          </h1>
        </header>
        <article>
          <p>In the previoux topics, we have looked at the expressive power of a GNN as the ability to solve a task. While these properties are informative about the network abilities, they are extrinsic. Indeed, the expressive power of the network is linked to its ability to work on a problem or approximate a function. Hopefully, a current line of work propose to analyze an intrinsic property of the GNNs, which is the spectral filtering power of the network filters.</p>
          <h3 class="post-title">
            <span class="font-weight-bold">Why spectral filtering as a expressive power property?</span>
          </h3>
          <p>To understand the importance of the spectral analysis of a filter, we first need to take a step back from the GNNs and speak about signal filtering. Let's take a 1D signal \(g:\mathbf{R}\longrightarrow\mathbf{C}\). This signal can be decomposed into different frequencies. The high frequency gives information about the rapidly evolving content of the signal, while the low frequency gives information about the content that stays locally constant. To decompose the signal, we use the Fourier transform:</p>
          <p style="text-align:center;">\(\begin{aligned}
                                              \hat{g}(\omega) = \int_{t\in \mathbf{R}} g(t) e^{-2\pi i \omega t} dt,\ \forall \omega \in \mathbf{R}
                                            \end{aligned}\)</p>
          <p>where \(\omega\) is the signal frequency. A relative high \(|\hat{g}(\omega)|\) value indicates that \(g\) encodes some significante information that oscillates at frequency \(\omega\).</p>
          <p>Now, let's take a 1D filter \(f:\mathbf{R}\longrightarrow\mathbf{C}\). We can notice that the Fourier transform of the convolution between the filter and the signal is a multiplication in the spectral domain:</p>
          <p style="text-align:center;">\(\begin{aligned}
                                              \hat{(f * g)}(\omega) = \hat{f}(\omega)\hat{g}(\omega),\ \forall \omega \in \mathbf{R}
                                            \end{aligned}\)</p>
          <p>Thus, convolving the signal \(g\) with the filter \(f\) is equivalent to a frequency selection. The filter \(f\) increases or decreases the frequency components of the signal. A filter can extract different information from a signal, focusing on some part of the signal spectrum. As a consequence, we can speak about the expressive power of a set of filter \(\{f\}_s\) as the spectrum range that they cover. The analysis of the filter frequencies informs us on the frequency information these filters can extract from the signal.</p>
          <h3 class="post-title">
            <span class="font-weight-bold">How spectral filtering work on graph?</span>
          </h3>
          <p>To apply the same Fourier analysis to graph filter, we need to extend the definition of Fourier transform to graph signal. This is nicely done by using the relation between the 1D Laplacian operator \(\Delta = -\frac{d^2}{dt^2}\) and the Fourier basis \(\{e^{-2\pi i \omega t}\}\):</p>
          <p style="text-align:center;">\(\begin{aligned}
                                              \Delta  e^{-2\pi i \omega t} = (2 \pi \omega)^2 e^{-2\pi i \omega t},\ \forall \omega \in \mathbf{R},\ \forall t \in \mathbf{R}
                                            \end{aligned}\)</p>
          <p>The Fourier basis are the eigenfunctions of the 1D Laplacian operator, where each eigenfunction \(e^{-2\pi i \omega t}\) oscillating at frequency \(\omega\) is associated to the eigenvalue \((2 \pi \omega)^2\).</p>
          <p>For signal living on a graph, we need to discretize the Laplacian operator through the Laplacian matrix \(L\) of the graph. This matrix depends on the graph and can tak different forms. For example, the normalized Lapalcian is widely used:</p>
          <p style="text-align:center;">\(\begin{aligned}
            \mathbf{L} = \mathbf{I} - \mathbf{D}^{-1/2}\mathbf{A}\mathbf{D}^{-1/2}
            \end{aligned}\)</p>
          <p> where \(\mathbf{I}\) is the identity matrix of size \(n\) the number of nodes, \(\mathbf{A}\) is the adjacency matrix and \(\mathbf{D}\) is the diagonal degree matrix. The normalized Laplacian has the nice property to have its eigenvalues in the range of \([0, 2]\).</p>
            <p>We can do a similar analysis of the 1D Laplacian operator, and find the eigenvectors of \(\mathbf{L}\). The Laplacian matrix is symmetric positive definite, and thus has real and positive eigenvalues \(\mathbf{\Lambda}=\{0=\lambda_1 \leq...\leq\lambda_n\}\) associated to real orthonormal eigenvectors \(\mathbf{U}=\{U_{\lambda_1},...,U_{\lambda_n}\}\).</p>
          <p style="text-align:center;">\(\begin{aligned}
            \mathbf{L} = \mathbf{U}^T diag(\mathbf{\Lambda}) \mathbf{U}
            \end{aligned}\)</p>
          <p>For a small eigenvalue \(\lambda\), the eigenfunction \(U_\lambda\) is a smooth signal on the graph, with low variation between two neighboring nodes. For a high eigenvalue \(\lambda\), the eigenfunction \(U_\lambda\) is a signal on the graph wit high variability between two neighboring nodes. We can see the eigenvalues as the graph frequencies and the associated eigenvectors as the Fourier basis for the graph signals.</p>
          <p>With this analogy in mind, we can extend the Fourier transform to signals on a graph. Let's take a signal \(g \in \mathbf{R}^n\), wich is a vector of size \(n\) with one value per node. Its Fourier transform is:</p>
          <p style="text-align:center;">\(\begin{aligned}
            \hat{g}(\lambda)&=\sum_{i} g(i) U_{\lambda}(i),\ \forall \lambda \in \mathbf{\Lambda} \\
            \hat{g} &= \mathbf{U}^T g
            \end{aligned}\)</p>
          <p>Then, the graph convolution arises naturally from its spectral definition. Let \(f \in \mathbf{R}^n\) be a graph filter. The Fourier transform of the convolution between \(f\) and \(g\) is: </p>
          <p style="text-align:center;">\(\begin{aligned}
                                              \hat{(f * g)}(\lambda) = \hat{f}(\lambda)\hat{g}(\lambda),\ \forall \lambda \in \mathbf{\Lambda}
                                            \end{aligned}\)</p>
          <p>Then, taking the inverse Fourier transform gives us the final convolution:</p>
          <p style="text-align:center;">\(\begin{aligned}
                                              (f * g) (i) &= \sum_{\lambda}\hat{f}(\lambda)\hat{g}(\lambda) U_{\lambda}(i),\ \forall i \in \mathcal{V} \\
                                              f * g &= \mathbf{U} diag(\hat{f}(\mathbf{\Lambda})) \mathbf{U}^T g
                                            \end{aligned}\)</p>
          <p>We can extend the Fourier analysis of 1D filter to graph filter, studying the vector \(\hat{f}(\mathbf{\Lambda})\).</p>
          <h3 class="post-title">
            <span class="font-weight-bold">Harmonic Analysis of localized graph filters</span>
          </h3>
          <p>In a spectral graph CNN, we are interested in learning the coefficient \(\hat{f}(\Lambda)\). There are two major drawbacks by doing so. The first is the learning complexity. Indeed, we learn \(O(n)\) coefficients, while for a traditional CNN the number of coefficients is \(O(1)\). The second is that these filters are not spatially localized. To overcome these problems, one can write the filter as a weighted sum of localized filters:</p>
          <p style="text-align:center;">\(\begin{aligned}
            \hat{f}(\Lambda)=\sum_{s=1}^S \theta_s \hat{f}_s(\Lambda)
            \end{aligned}\)</p>
          <p>where \(\theta_s \in \mathbf{R}\) are the learnt parameters of the filter and \(g_s\) are known functions of the eigenvalue \(\lambda\) wit possible learnt parameters independent of the number of nodes. Introducing this filter into the convolution gives:</p>
          <p style="text-align:center;">\(\begin{aligned}
                f * g = \sum_{s=1}^S \theta_s \mathbf{U} diag(\hat{f}_s(\Lambda)) \mathbf{U}^T g
              \end{aligned}\)</p>
          <p>The convolution support is defined as \(\mathbf{C}_s=\mathbf{U} diag(\hat{f}_s(\Lambda)) \mathbf{U}^T\), which describes how the nodes of a neighborhood are aggregated to update the central node. We can study the expressive power of the graph CNN by studying the spectrum of the convolution support, which correspond to:</p>
          <p style="text-align:center;">\(\begin{aligned}
                f_s(\Lambda) = diag^{-1}(\mathbf{U}^T \mathbf{C}_s \mathbf{U})
              \end{aligned}\)</p>
          <p>This analysis is well-suited for Spectral Convolution, where the convolution support is well-defined and we are sure that \(\mathbf{U}^T \mathbf{C}_s \mathbf{U}\) is a diagonal matrix.</p>

          <div class="publications">
            <h3 class="post-title">
              <span class="font-weight-bold">Bibliography</span>
            </h3>
            <h2 class="year">2021</h2>
            <ol class="bibliography">
              <li>
                <div class="row">
                  <div id="balcilar2021" class="col-sm-8">
                    <div class="title">Analyzing the Expressive Power of Graph Neural Networks in a Spectral Perspective</div>
                    <div class="author">
                      <em>Balcilar, M.</em>,
                      Renton, G.,
                      Heroux, P.,
                      Gauzere, B.,
                      Adam, S.,
                      and Honeine, P.
                    </div>
                    <div class="periodical">
                      <em>In ICLR</em>
                      2021
                    </div>
                    <div class="links">
                      <a href="https://openreview.net/pdf?id=-qh0M9XWxnv" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
                      <a href="https://github.com/balcilar/gnn-spectral-expressive-power" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
                    </div>
                  </div>
                </div>
              </li>
            </ol>
            <h2 class="year">2020</h2>
            <ol class="bibliography">
              <li>
                <div class="row">
                  <div id="oono2020" class="col-sm-8">
                    <div class="title">Graph Neural Networks Exponentially Lose Expressive Power for Node Classification</div>
                    <div class="author">
                      <em>Oono, K.</em>,
                      and Suzuki, T.
                    </div>
                    <div class="periodical">
                      <em>In ICLR</em>
                      2020
                    </div>
                    <div class="links">
                      <a href="https://openreview.net/pdf?id=S1ldO2EFPr" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
                      <a href="https://github.com/delta2323/gnn-asymptotics" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
                    </div>
                  </div>
                </div>
              </li>
              <li>
                <div class="row">
                  <div id="nt2019" class="col-sm-8">
                    <div class="title">Revisiting Graph Neural Networks: All We Have is Low-Pass Filters</div>
                    <div class="author">
                      <em>NT, H.</em>,
                      and Maehara, T.
                    </div>
                    <div class="periodical">
                      <em>In ICPR</em>
                      2020
                    </div>
                    <div class="links">
                      <a href="https://arxiv.org/pdf/1905.09550.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
                      <a href="https://github.com/gear/gfnn" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
                    </div>
                  </div>
                </div>
              </li>
            </ol>
            <h2 class="year">2019</h2>
            <ol class="bibliography">
              <li>
                <div class="row">
                  <div id="wu2019" class="col-sm-8">
                    <div class="title">Simplifying Graph Convolutional Networks</div>
                    <div class="author">
                      <em>Wu, F.</em>,
                      <em>Zhang, Z</em>,
                      <em>Holanda de Souza Jr., Q.</em>,
                      Fifty, C.,
                      Yu, T.,
                      and Weinberger, K.
                    </div>
                    <div class="periodical">
                      <em>In ICML</em>
                      2019
                    </div>
                    <div class="links">
                      <a href="https://arxiv.org/pdf/1902.07153.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
                      <a href="https://github.com/Tiiiger/SGC" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
                    </div>
                  </div>
                </div>
              </li>
            </ol>
            <h2 class="year">2018</h2>
            <ol class="bibliography">
              <li>
                <div class="row">
                  <div id="li2018" class="col-sm-8">
                    <div class="title">Deeper insights into graph convolutional networks for semi-supervised learning</div>
                    <div class="author">
                      <em>Li, Q.</em>,
                      Han, Z.,
                      and Wu, X-M.
                    </div>
                    <div class="periodical">
                      <em>In AAAI</em>
                      2018
                    </div>
                    <div class="links">
                      <a href="https://arxiv.org/pdf/1801.07606.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
                    </div>
                  </div>
                </div>
              </li>
            </ol>
          </div>
        </article>
      </div>
    </div>
    <footer class="fixed-bottom">
      <div class="container mt-0">
        &copy; Copyright 2021 Axel Elald.
        Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.
      </div>
    </footer>
  </body>
  <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha512-/DXTXr6nQodMUiq+IUJYCt2PPOUjrHJ9wFrqpJ3XkgPNOZVfMok7cRw6CSxyCQxXn6ozlESsSh1/sMCTF1rL/g==" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js"  integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>
  <script src="/graph-power/assets/js/common.js"></script>
  <link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />
  <script src="https://cdnjs.cloudflare.com/ajax/libs/masonry/4.2.2/masonry.pkgd.min.js" integrity="" crossorigin="anonymous"></script>
  <script src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script type="text/javascript">
    // Init Masonry
    var $grid = $('.grid').masonry({
      gutter: 10,
      horizontalOrder: true,
      itemSelector: '.grid-item',
    });
    // layout Masonry after each image loads
    $grid.imagesLoaded().progress( function() {
      $grid.masonry('layout');
    });
  </script>  
</html>



